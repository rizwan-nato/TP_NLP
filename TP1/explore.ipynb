{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJiP8CpciCsk"
      },
      "source": [
        "# Collab stuff to link git and google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5dx4R0_pijH",
        "outputId": "a217423e-dfe2-47ac-ad63-348b38a2b756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Github\n",
            "/content/drive/MyDrive/Github/TP_NLP/TP1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Github/\n",
        "git_token =   #Generate an access token\n",
        "username = \"rizwan-nato\"\n",
        "repository = \"TP_NLP\"\n",
        "!git config --global user.email \"rizwanato@hotmail.fr\"\n",
        "!git config --global user.name \"Rizwan Nato\"\n",
        "#!git clone https://{git_token}@github.com/{username}/{repository}\n",
        "%cd /content/drive/MyDrive/Github/TP_NLP/TP1\n",
        "#!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g50shORIvBz7"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0tcT6C4NnEjD"
      },
      "outputs": [],
      "source": [
        "from skipGram import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w3Nyu86ZtEOf"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import pearsonr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xVZ9K230nEjG"
      },
      "outputs": [],
      "source": [
        "def run_training(sg, Number_of_epochs, Learning_rate_Schedule, early_stopping = 1e-3):\n",
        "  for i, lr in zip(range(Number_of_epochs), Learning_rate_Schedule):\n",
        "    sg.train(epochs=1, lr=lr)\n",
        "    pairs = loadPairs(\"simlex.csv\")\n",
        "    Y_true = []\n",
        "    Y_pred = []\n",
        "    Y_true2 = []\n",
        "    Y_pred2 = []\n",
        "    for a, b, y_true in pairs:\n",
        "      pred, unknown = sg.similarity(a,b)\n",
        "      Y_pred.append(pred)\n",
        "      Y_true.append(y_true)\n",
        "      if not unknown:\n",
        "        Y_pred2.append(pred)\n",
        "        Y_true2.append(y_true)\n",
        "    Y_pred = np.array(Y_pred)\n",
        "    Y_true = np.array(Y_true)\n",
        "    Y_pred2 = np.array(Y_pred2)\n",
        "    Y_true2 = np.array(Y_true2)\n",
        "\n",
        "    pairs = loadPairs(\"simlex.csv\")\n",
        "    Y_true_combine = []\n",
        "    Y_pred_combine = []\n",
        "    Y_true2_combine = []\n",
        "    Y_pred2_combine = []\n",
        "    for a, b, y_true in pairs:\n",
        "      pred, unknown = sg.similarity(a,b, combine_embed=True)\n",
        "      Y_pred_combine.append(pred)\n",
        "      Y_true_combine.append(y_true)\n",
        "      if not unknown:\n",
        "        Y_pred2_combine.append(pred)\n",
        "        Y_true2_combine.append(y_true)\n",
        "    Y_pred_combine = np.array(Y_pred_combine)\n",
        "    Y_true_combine = np.array(Y_true_combine)\n",
        "    Y_pred2_combine = np.array(Y_pred2_combine)\n",
        "    Y_true2_combine = np.array(Y_true2_combine)\n",
        "    print(f\"There are {len(Y_true) - len(Y_true2)} unknown words\")\n",
        "    print(\"     > Correlation on all words:\", pearsonr(Y_true, Y_pred), pearsonr(Y_true_combine, Y_pred_combine))\n",
        "    print(\"     > Correlation on known words:\", pearsonr(Y_true2, Y_pred2), pearsonr(Y_true2_combine, Y_pred2_combine))\n",
        "    if i > 0:\n",
        "      if sg.loss[-2] - sg.loss[-1] < early_stopping:\n",
        "        print(\"Early stopping..\")\n",
        "        break;\n",
        "  return pearsonr(Y_true, Y_pred), pearsonr(Y_true_combine, Y_pred_combine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PqN0krqSt0u2"
      },
      "outputs": [],
      "source": [
        "Learning_rate_Schedule =  [1e-2]*100\n",
        "Number_of_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_dict = {}\n",
        "number_of_line = 5000\n",
        "sentences_no_lemma = text2sentences(\"train_full_24.txt\", number_of_line=number_of_line, lemma=False)\n",
        "sentences_with_lemma = text2sentences(\"train_full_24.txt\", number_of_line=number_of_line, lemma=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H3poIUTlmBy",
        "outputId": "29dc72f7-e8a1-475d-cf9d-d1fffbbb1c61"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [01:32<00:00, 53.96it/s]\n",
            "100%|██████████| 5000/5000 [01:25<00:00, 58.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(\"correlation5000.dict\", 'wb') as f:\n",
        "#   pickle.dump(correlation_dict, f)"
      ],
      "metadata": {
        "id": "LCzdi7R0ofVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"correlation5000.dict\", \"rb\") as f:\n",
        "  correlation_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "zSctWKxZmF1V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJOSI22TmdFh",
        "outputId": "b25f5ac9-fef8-4748-92fd-d65f59b56e3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15eLSYVwzWcP",
        "outputId": "e5365a17-8882-49cb-8b12-346284dcec35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############################################################################\n",
            "Training model: miniCount 5 nEmbed 100 winSize 9 Lemma False\n",
            "Training Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 447/5000 [00:11<02:23, 31.69it/s]"
          ]
        }
      ],
      "source": [
        "nEmbed = 100\n",
        "for winSize in [9,5,3]:\n",
        "  for minCount in [5,2]:\n",
        "    for i, sentence in enumerate([sentences_no_lemma, sentences_with_lemma]):\n",
        "      print(\"############################################################################\")\n",
        "      print(f\"Training model: miniCount {minCount} nEmbed {nEmbed} winSize {winSize} Lemma {i==1}\")\n",
        "      if f\"miniCount {minCount} nEmbed {nEmbed} winSize {winSize} Lemma {i==1} Not combined\" in correlation_dict:\n",
        "        print(\"Already Trained Skipping... \\n\")\n",
        "        continue\n",
        "      sg = SkipGram(sentences=sentence, minCount=minCount, nEmbed=nEmbed, winSize=winSize, negativeRate=5)\n",
        "      correlation, correlation_combine = run_training(sg, Number_of_epochs, Learning_rate_Schedule)\n",
        "      correlation_dict[f\"miniCount {minCount} nEmbed {nEmbed} winSize {winSize} Lemma {i==1} Not combined\"] =  correlation\n",
        "      correlation_dict[f\"miniCount {minCount} nEmbed {nEmbed} winSize {winSize} Lemma {i==1} Combined\"] =  correlation_combine\n",
        "      print(\"     Saving Correlation\")\n",
        "      with open(\"correlation5000.dict\", 'wb') as f:\n",
        "          pickle.dump(correlation_dict, f)\n",
        "      word1 = \"president\"\n",
        "      Similarity = []\n",
        "      for word2 in sg.vocab:\n",
        "        Similarity.append((word2, sg.similarity(word1,word2)))\n",
        "      b = sorted(Similarity, key=lambda Similarity:Similarity[1])\n",
        "      print(\"\\n\")\n",
        "      print(\"Words closest and furthest away from president\")\n",
        "      print(b[-20:])\n",
        "      print(b[:20])\n",
        "      print(\"\\n\")\n",
        "      print(\"\\n\")\n",
        "    # sg.save(f\"Models/NoLemma/miniCount{minCount}_nEmbed{nEmbed}_winSize{winSize}.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaNBq7VifF2T"
      },
      "outputs": [],
      "source": [
        "word1 = \"president\"\n",
        "Similarity = []\n",
        "for word2 in sg.vocab:\n",
        "  Similarity.append((word2, sg.similarity(word1,word2)))\n",
        "\n",
        "b = sorted(Similarity, key=lambda Similarity:Similarity[1])\n",
        "print(b[-50:])\n",
        "print(b[:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeBXhgFPwSwf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "explore_TP_NLP1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "382107c779457b1d5f37b942fa2b1e8e6741e026e15e9bf2fbf744eb8b924541"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
