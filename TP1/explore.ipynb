{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skipGram import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = text2sentences(\"train.txt\")\n",
    "sg = SkipGram(sentences, minCount=1, nEmbed=300, epochs=1, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1\n",
      " > training 0 of 1000\n",
      "    > loss 5.86025818278546\n",
      " > training 100 of 1000\n",
      "    > loss 4.925272166624081\n"
     ]
    }
   ],
   "source": [
    "sg.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = loadPairs(\"simlex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b, y_true in pairs:\n",
    "    # make sure this does not raise any exception, even if a or b are not in sg.vocab\n",
    "    pred = sg.similarity(a,b)\n",
    "    if pred == 0.5:\n",
    "        compteur += 1\n",
    "    print(pred, y_true)\n",
    "    Y_pred.append(pred*10)\n",
    "    Y_true.append(y_true)\n",
    "Y_pred = np.array(Y_pred)\n",
    "Y_true = np.array(Y_true)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "382107c779457b1d5f37b942fa2b1e8e6741e026e15e9bf2fbf744eb8b924541"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
